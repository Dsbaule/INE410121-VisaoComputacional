{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ddf4cc",
   "metadata": {},
   "source": [
    "# Sketch2aia - Abordagem com *Deep Learning*\n",
    "\n",
    "Para a abordagem utilizando *Deep Learning*, se optou pela utilização do YoloV5 devido aos bons resultados obtidos anteriormente com YoloV3 e YoloV4, sua boa performance em geral e o baixo impacto de seus principais pontos fracos no problema em questão.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe784a7",
   "metadata": {},
   "source": [
    "## YoloV5\n",
    "\n",
    "YOLO (*You Only Look Once*) é um algoritmo de detecção de objetos que divide a imagem em um sistema de grades, com cada célula na grade sendo responsável pela detecção de objetos dentro de si:\n",
    "\n",
    "<img src=\"media/YoloDog.png\" width=600/>\n",
    "\n",
    "Desde sua criação, o modelo YOLO se tornou um dos modelos de detecção de objetos mais famosos, devido a sua velocidade e acurácia.\n",
    "\n",
    "A equipe já havia realizado experimentos com YoloV3 e YoloV4, obtendo bons resultados, logo, foi decidido utilizar o YoloV5, onde o modelo YOLO foi então introduzido ao framework PyTorch.\n",
    "\n",
    "São disponibilizados diversos modelos de YoloV5, com modelos mais simples focando em maior velocidade de processamento de imagens ou uso de memória, enquanto os modelos maiores tem maior foco em acurácia:\n",
    "\n",
    "<img src=\"media/YoloModels.png\" width=600/>\n",
    "\n",
    "<img src=\"media/YoloModelsPerformance.png\" width=600/>\n",
    "\n",
    "Foram realizados testes com diversos modelos, com os melhores resultados sendo obtidos com o `Yolov5m6`:\n",
    "\n",
    "![Model Tests](media/YoloModelsTests.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f4717",
   "metadata": {},
   "source": [
    "## Conjunto de Dados\n",
    "\n",
    "Para o treinamento do classificador, e para a realização de testes, foi preparado um conjunto de dados de *sketches* de interfaces de usuário, feitos com base em *screenshot* de aplicativos App Inventor:\n",
    "\n",
    "| Screenshot                              | *Sketch*\n",
    "| :-------------------------------------: | :--------------------------------------:\n",
    "| <img src=\"media/ExampleScreenshot1.png\" width=256/> | <img src=\"media/ExampleSketch1.jpg\" width=256/>\n",
    "\n",
    "Foram selecionados originalmente *screenshots* com apenas os 9 componentes mais comuns em aplicativos de App Inventor<a name=\"cite_ref-1\"></a>[<sup>[1]</sup>](#cite_note-1), visando simplificar a tarefa de classificação destes, visto que outros componentes muito pouco utilizados são visualmente muito parecidos em *sketches*:\n",
    "\n",
    "| Label                                   | Button                                   | TextBox\n",
    "| :-------------------------------------: | :--------------------------------------: | :----:\n",
    "| <img src=\"media/Label1.jpg\" width=256/> | <img src=\"media/Botao1.jpg\" width=256/>  | <img src=\"media/TextBox1.jpg\" width=256/> \n",
    "\n",
    "| Checkbox                                | Slider                                   | ListPicker\n",
    "| :-------------------------------------: | :--------------------------------------: | :----:\n",
    "| <img src=\"media/Checkbox1.jpg\" width=256/> | <img src=\"media/Slider1.jpg\" width=256/> | <img src=\"media/ListPicker1.jpg\" width=256/>\n",
    "\n",
    "| Switch                                   | Image                                    | Map\n",
    "| :-------------------------------------:  | :--------------------------------------: | :----:\n",
    "| <img src=\"media/Switch1.jpg\" width=256/> | <img src=\"media/Image1.jpg\" width=256/>  | <img src=\"media/Map1.jpg\" width=256/>\n",
    "\n",
    "Com a ajuda de voluntários, foram coletados *sketches* com base nestes *screenshots* selecionados, gerando assim um conjunto de dados completo com diversos estilos de desenho e com variação de câmera e condições luminosas:\n",
    "\n",
    "<table><tr>\n",
    "    <td> <img src=\"media/ExampleSketch2.jpg\" width=256/> </td>\n",
    "    <td> <img src=\"media/ExampleSketch3.jpg\" width=256/> </td>\n",
    "    <td> <img src=\"media/ExampleSketch4.jpg\" width=256/> </td>\n",
    "</tr></table>\n",
    "\n",
    "Os *sketches* feitos pelos voluntários foram então rotulados manualmente, com anotações de posição e tipo de cada componente, bem como a posição da tela (*screen*) como um todo:\n",
    "\n",
    "<img src=\"media/Annotations.png\" width=600/>\n",
    "\n",
    "Resultando em um conjunto de dados com 402 imagens de *sketches* de interfaces de usuário, com anotações de 3584 componentes:\n",
    "\n",
    "![Class Balance](media/ClassBalance2.png)\n",
    "\n",
    "Estas foram divididas em conjuntos de treino, validação e testes com as seguintes proporções<a name=\"cite_ref-1\"></a>[<sup>[1]</sup>](#cite_note-1):\n",
    "\n",
    "![Split](media/Split2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18aae85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dsbau\\OneDrive\\Documents\\UFSC\\Mestrado\\2o Semestre\\INE410121 - Visão Computacional\\INE410121-VisaoComputacional\\yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Setup complete. Using torch 1.10.2+cpu (CPU)\n"
     ]
    }
   ],
   "source": [
    "# Clone YOLOv5 and install dependencies\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt # install dependencies\n",
    "%pip install -q roboflow\n",
    "\n",
    "# Import libs\n",
    "import torch\n",
    "import os\n",
    "from IPython.display import Image, clear_output\n",
    "\n",
    "# Check if cuda enabled\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "891b380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model\n",
    "os.environ[\"MODEL_NAME\"] = \"yolov5m6\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41876ef2",
   "metadata": {},
   "source": [
    "## Avaliação do Modelo\n",
    "\n",
    "Métricas do treinamento do modelo podem ser obtidas por meio do Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e862be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python val.py --weights ../yolov5m6/weights/best.pt --data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
